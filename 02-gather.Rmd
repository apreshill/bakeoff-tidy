---
title: "Gather to Tidy Data"
author: "Alison Hill & Daniel Anderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
---

This is a lesson on tidying data, remixed from [Jenny Bryan's similar lesson using "Lord of the Rings" data](https://github.com/jennybc/lotr-tidy). Most text + code is Jenny's, basically we plopped a new dataset in there `r emo::ji("wink")`

---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(error = TRUE, collapse = TRUE, comment = "#>", warning = FALSE, message = FALSE)
```

An important aspect of "writing data for computers" is to make your data __tidy__. Key features of __tidy__ data:

  * Each column is a variable
  * Each row is an observation

But unfortunately, __untidy__ data abounds. In fact, we often inflict it on ourselves, because untidy formats are more attractive for data entry or examination. So how do you make __untidy__ data __tidy__?

## Import 

We now import the untidy data from the eight series that was presented in [the intro](01-intro.md).

I assume that data can be found as eight plain text, delimited files, one for each film, each with the filename `series*.csv`. How to liberate data from spreadsheets or tables in word processing documents is beyond the scope of this tutorial. 

The files live here in this repo, which you could clone as a new RStudio Project. We'll use a neat trick to read in all 8 csv files at once:

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">‚òùÔ∏è My first <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> tip: use purrr::map_df() to read all .csv files in a üìÇ and stick them in a single data frame:<br><br>f &lt;- list.files(<br>  &quot;my_folder&quot;,<br>   pattern = &quot;*.csv&quot;,<br>   full.names = TRUE)<br><br>d &lt;- purrr::map_df(f, readr::read_csv, .id = &quot;id&quot;) <a href="https://t.co/JWxI5ecr0k">pic.twitter.com/JWxI5ecr0k</a></p>&mdash; We are R-Ladies (@WeAreRLadies) <a href="https://twitter.com/WeAreRLadies/status/1034817323922804737?ref_src=twsrc%5Etfw">August 29, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>


You do not need to know how the below code works- please treat it like a magic black box for now! You'll learn more about these packages and functions in the third course of this series.


```{r results='hide'}
library(tidyverse)
bakes_untidy <- fs::dir_ls(path = here::here("data"), 
                          regexp = "series\\d.csv") %>% 
  purrr::map_df(readr::read_csv)
```



We now have one data frame with bake counts for all 8 series, across both the signature and showstopper challenges.

```{r}
bakes_untidy
glimpse(bakes_untidy)
```

Assembling one large data object from lots of little ones is common data preparation task. When the pieces are as similar as they here, it's nice to assemble them into one object right away. In other scenarios, you may need to do some remedial work on the pieces before they can be fitted together nicely.

A good guiding principle is to glue the pieces together as early as possible, because it's easier and more efficient to tidy a single object than 20 or 1000.

## Tidy 

We are still violating one of the fundamental principles of __tidy data__. "Bake count" is a fundamental variable in our dataset and it's currently spread out over two variables, `cake` and `pie_tart`. Conceptually, we need to gather up the bake counts into a single variable and create a new variable, `n_bakes`, to track whether each count refers to cakes or pies/tarts. We use the `gather()` function from the tidyr package to do this.

```{r}
bakes_tidy <-
  gather(bakes_untidy, key = 'type_bake', value = 'n_bakes', cake, pie_tart)
bakes_tidy
```

Tidy data ... mission accomplished!

To explain our call to `gather()` above, let's read it from right to left: we took the variables `cake` and `pie_tart` and gathered their *values* into a single new variable `n_bakes`. This forced the creation of a companion variable `type_bake`, a *key*, which tells whether a specific value of `n_bakes` came from `cake` or `pie_tart`. All other variables, such as `challenge`, remain unchanged and are simply replicated as needed. The documentation for `gather()` gives more examples and documents additional arguments.

## Export

Now we write this multi-series, tidy dataset to file for use in various downstream scripts for further analysis and visualization. This would make an excellent file to share on the web with others, providing a tool-agnostic, ready-to-analyze entry point for anyone wishing to play with this data.

```{r}
write_csv(bakes_tidy, path = file.path("data", "bakes_tidy.csv")) 
```

You can inspect this delimited file here: [bakes_tidy.csv](data/bakes_tidy.csv).

## Exercises

Choose one of three tidying adventures:

### `Bachelorette`

Follow along with these code prompts:

* Use the following code to read in data used from several stories from [538](https://github.com/fivethirtyeight/data/tree/master/bachelorette) (Note: you'll get a bunch of parsing errors and that is OK to ignore):

```{r}
bach <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/bachelorette/bachelorette.csv",
                         col_types = cols(SEASON = col_integer()))
```

* Create a dataset that looks like this:

```{r echo = FALSE}
b_tidy <- bach %>% 
  filter(!SEASON == "SEASON") %>% 
  select(SHOW, SEASON, CONTESTANT, starts_with("ELIMINATION")) %>% 
  gather(key = "week", value = "eliminated", starts_with("ELIMINATION"), na.rm = TRUE) %>% 
  mutate(week = str_replace(week, "-", "_"),
         week = parse_number(week))
b_tidy
```

Use this code template if you want some help getting there:

```{r eval = FALSE}
b_tidy <- bach %>% 
  filter(!SEASON == "SEASON") %>% 
  select(SHOW, SEASON, CONTESTANT, starts_with("ELIMINATION")) %>% 
  gather(key = <what is the key var you want?>, 
         value = <what is the value var you want?>, 
         <select which vars you want to gather?>, 
         na.rm = TRUE) %>% 
  mutate(week = str_replace(week, "-", "_"),
         week = parse_number(week))
b_tidy
```




* Use the tidy dataset to answer the following questions:

1. How many contestants were eliminated in week 3? What about for the Bachelor vs. the Bachelorette?
1. Make a plot of the number of roses, facetted by show.

```{r, echo = FALSE}
b_roses <- b_tidy %>% 
  filter(eliminated %in% c("R1", "R")) 
ggplot(b_roses, aes(x = SEASON)) +
  geom_bar() +
  facet_wrap(~ SHOW)
```

### PDX Bike Counts

update this link once up on github

```{r}
untidy_bikes <- read_csv("https://raw.githubusercontent.com/apreshill/bakeoff-tidy/master/data/untidy-bike-counts.csv")
```


## 538 Flying Etiquette Survey

```{r}
untidy_flying <- read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/flying-etiquette-survey/flying-etiquette.csv")

# Fill in code below
rude_tidy <- flying %>% 
    # Change characters to factors
    mutate_if(is.character, as.factor) %>%
    # Filter out those who have never flown on a plane
    filter(`How often do you travel by plane?` != "Never") %>% 
    # select columns containing "rude"
    select(RespondentID, contains("rude")) %>%
    # change format from wide to long
    gather(response_var, value, -RespondentID) %>% 
  mutate(rude = if_else(str_detect(value, "Yes"), 1, 0))


# Make a two column dataset with variable names and number of levels
number_of_levels <- responses_as_factors %>% 
  summarise_all(nlevels) %>%
  gather(variable, num_levels)

mtcars %>%
  top_n(2, mpg) %>%
  pull(mpg)
```



The word count data is given in these two __untidy__ and gender-specific files:

  * [Female.csv](data/Female.csv)
  * [Male.csv](data/Male.csv)
  
Write an R script that reads them in and writes a single tidy data frame to file. Literally, reproduce the `lotr_tidy` data frame and the `lotr_tidy.csv` data file from above.

Write R code to compute the total number of words spoken by each race across the entire trilogy. Do it two ways:

  * Using film-specific or gender-specific, untidy data frames as the input data.
  * Using the `lotr_tidy` data frame as input.

Reflect on the process of writing this code and on the code itself. Which is easier to write? Easier to read?

Write R code to compute the total number of words spoken in each film. Do this by copying and modifying your own code for totalling words by race. Which approach is easier to modify and repurpose -- the one based on multiple, untidy data frames or the tidy data?

## Take home message

It is untidy to have have data parcelled out across different files or data frames. We used `dplyr::bind_rows()` above to combine film-specific data frames into one large data frame.

It is untidy to have a conceptual variable, e.g. "word count", spread across multiple variables, such as word counts for males and word counts for females. We used the `gather()` function from the tidyr package to stack up all the word counts into a single variable, create a new variable to convey male vs. female, and  do the replication needed for the other variables.

Many data analytic projects will benefit from a script that marshals data from different files, tidies the data, and writes a clean result to file for further analysis.

Watch out for how __untidy__ data seduces you into working with it more than you should:

  * Data optimized for consumption by human eyeballs *is* attractive, so it's hard to remember it's suboptimal for computation. How can something that looks so pretty be so wrong?
  * Tidy data often has lots of repetition, which triggers hand-wringing about efficiency and aesthetics. Until you can document a performance problem, keep calm and tidy on.
  * Tidying operations are unfamiliar to many of us and we avoid them, subconsciously preferring to faff around with other workarounds that are more familiar.

### Where to next?

In the next lesson [03-spread](03-spread.md) I show to untidy data, using `spread()` from the tidyr package. This might be useful at the end of an analysis, for preparing figures or tables.

In the [optional bonus content](04-tidy-bonus-content.md), I show how to tidy this data using only base R functions.

### Resources

  * [Tidy data](http://r4ds.had.co.nz/tidy-data.html) chapter in R for Data Science, by Garrett Grolemund and Hadley Wickham
    - [tidyr](https://github.com/hadley/tidyr) R package
    - The tidyverse meta-package, within which `tidyr` lives: [tidyverse](https://github.com/hadley/tidyversee).
  * [Bad Data Handbook](http://shop.oreilly.com/product/0636920024422.do) by By Q. Ethan McCallum, published by O'Reilly.
    - Chapter 3: Data Intended for Human Consumption, Not Machine Consumption by Paul Murrell.
  * Nine simple ways to make it easier to (re)use your data by EP White, E Baldridge, ZT Brym, KJ Locey, DJ McGlinn, SR Supp. *Ideas in Ecology and Evolution* 6(2): 1‚Äì10, 2013. doi:10.4033/iee.2013.6b.6.f <http://library.queensu.ca/ojs/index.php/IEE/article/view/4608>
    - See the section "Use standard table formats"
  * Tidy data by Hadley Wickham. Journal of Statistical Software. Vol. 59, Issue 10, Sep 2014. <http://www.jstatsoft.org/v59/i10>
